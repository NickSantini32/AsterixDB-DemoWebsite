# AsterixDB-DemoWebsite
A small independent web application meant to showcase the simplicity and scalability of AsterixDB

# Documentation Videos
* [General Project Overview](https://youtu.be/Czh94ciT02A)
* [Technical JS Overview](https://youtu.be/-zvdzW8AyWw) (slightly outdated)
* [AsterixDB database backend structure](https://youtu.be/sWA4ee0NduU)

# Setup Instructions
* Download the simple server package of AsterixDB from their website [here](https://asterixdb.apache.org/download.html)
* In the extracted asterix-server directory, navigate to opt/local/bin/ in the terminal and run 'sh start-sample-cluster.sh' for mac and start-sample-cluster.bat for windows
* For the first dataset use the included sampleCrimeData.csv file
* For the second dataset use the included TIGER2018_ZCTA5.json file
* Both of these datasets are small samples of datasets that can be found [here](https://data.lacity.org/Public-Safety/Crime-Data-from-2010-to-2019/63jg-8b9z) for the crimes and [here](https://star.cs.ucr.edu/?TIGER2018/ZCTA5#center=33.9578,-118.1739&zoom=11) for the zip codes
* Go to http://localhost:19006/ and paste then run the following SQL query

IMPORTANT NOTE: Make sure to change the file path to that of your own dataset
```
use csv;
drop dataset csv_set if exists;
drop type csv_type if exists;

create type csv_type as {
	id:uuid,
    DR_NO: int32,
    Date_Rptd: string,
    Date_OCC: string,
    Time_OCC: string,
    Area: string,
    Area_Name: string,
    Rpt_Dist_No: int32,
    Part_12: string,
    Crm_Cd: string,
    Crm_Cd_Desc: string,
    Mocodes: string,
    Vict_Age: int32,
    Vict_Sex: string,
    Vict_Descent: string,
    Premis_Cd: string,
    Premis_Desc: string,
    Weapon_Used_Cd: string,
    Weapon_Desc: string,
    Status: string,
    Status_Desc: string,
    Crm_Cd_1: string,
    Crm_Cd_2: string,
    Crm_Cd_3: string,
    Crm_Cd_4: string,
    LOCATION: string,
    Cross_Street: string,
    lat: double,
    long: double
};

create dataset csv_set (csv_type) primary key id autogenerated;


load dataset csv_set using localfs
    (("path"="127.0.0.1:///YOUR/PATH/TO/sampleCrimeData.csv"),
    ("input-format"="text-input-format"),
    ("format"="delimited-text"),
    ("delimiter"=","),
    ("NULL"=""));

upsert into csv_set (
  SELECT parse_datetime(c.Date_Rptd, "M/D/Y h:m:s a") as Datetime_Rptd,
  parse_datetime(c.Date_OCC, "M/D/Y h:m:s a") as Datetime_OCC, c.*
  FROM csv_set c
);

-- zip dataset
use csv;
drop dataset csv_zipset if exists;
drop type csv_ziptype if exists;

create type csv_ziptype as {
	id: uuid,
	g:geometry
};

create dataset csv_zipset (csv_ziptype) primary key id autogenerated;

load dataset csv_zipset using localfs
    (("path"="127.0.0.1:///YOUR/PATH/TO/TIGER2018_ZCTA5.json"),
    ("input-format"="text-input-format"),
    ("format"="adm"),
    ("NULL"=""));
```
* then open index.html in the build folder

# If you plan on developing with this
* Install [the latest version of Node.js](https://nodejs.org/en/)
* Open the repo directory in your terminal and run the following commands
* 'npm install'
* 'npm start'
* The development webpage should now open

# Some known issues
* there is no indication that the website is processing / loading. I would have liked to add this if I had more time
* When working with large datasets (like the full ~10M line LA crime set) the website bogs down and is very slow. It does eventually work but as stated above, there is no communication that it is loading. 